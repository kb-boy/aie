{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70bcc74",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    selection_rate,\n",
    "    true_positive_rate\n",
    ")\n",
    "\n",
    "path = kagglehub.dataset_download(\"spscientist/students-performance-in-exams\")\n",
    "dataset_file = os.path.join(path, 'StudentsPerformance.csv')\n",
    "df = pd.read_csv(dataset_file)\n",
    "\n",
    "\n",
    "# --- Step 2: Basic preprocessing ---\n",
    "# Encode categorical features\n",
    "label_enc = LabelEncoder()\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = label_enc.fit_transform(df[col])\n",
    "\n",
    "# Create target variable: 1 if passed math (>50), else 0\n",
    "df['passed_math'] = (df['math score'] >= 50).astype(int)\n",
    "\n",
    "# Sensitive attribute (you can change to another column like 'race/ethnicity')\n",
    "sensitive_feature = 'gender'\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['math score', 'passed_math'])\n",
    "y = df['passed_math']\n",
    "\n",
    "# --- Step 3: Train-test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 4: Standardize features ---\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# --- Step 5: Train model ---\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# --- Step 6: Model performance ---\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {acc:.3f}\")\n",
    "\n",
    "# --- Step 7: Fairlearn MetricFrame ---\n",
    "mf = MetricFrame(\n",
    "    metrics={\n",
    "        'accuracy': accuracy_score,\n",
    "        'selection_rate': selection_rate,\n",
    "        'true_positive_rate': true_positive_rate,\n",
    "    },\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=df.loc[y_test.index, sensitive_feature]\n",
    ")\n",
    "\n",
    "print(\"\\n=== Fairness Metrics by Sensitive Group ===\")\n",
    "print(mf.by_group)\n",
    "\n",
    "# --- Step 8: Equal Opportunity Difference ---\n",
    "eo_diff = mf.difference(method='between_groups')['true_positive_rate']\n",
    "print(f\"\\nEqual Opportunity Difference: {eo_diff:.3f}\")\n",
    "\n",
    "# --- Step 9: Disparate Impact ---\n",
    "# Ratio of minimum to maximum selection rate across groups\n",
    "sr = mf.by_group['selection_rate']\n",
    "disparate_impact = sr.min() / sr.max()\n",
    "print(f\"Disparate Impact (min/max selection rate): {disparate_impact:.3f}\")\n",
    "\n",
    "# --- Step 10: Predictive Parity ---\n",
    "# Precision parity = ratio or difference of precision between groups\n",
    "precision = {}\n",
    "for g in df[sensitive_feature].unique():\n",
    "    y_true_g = y_test[df.loc[y_test.index, sensitive_feature] == g]\n",
    "    y_pred_g = y_pred[df.loc[y_test.index, sensitive_feature] == g]\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_g, y_pred_g).ravel()\n",
    "    precision[g] = tp / (tp + fp + 1e-9)\n",
    "print(f\"\\nPredictive Parity by Group: {precision}\")\n",
    "\n",
    "# --- Step 11: Threshold Limit Analysis ---\n",
    "print(\"\\n=== Threshold Fairness Check ===\")\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_prob >= t).astype(int)\n",
    "    tpr = true_positive_rate(y_test, y_pred_t)\n",
    "    print(f\"Threshold {t:.1f}: True Positive Rate = {tpr:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
